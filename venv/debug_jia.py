# debug_jia.py - ì§€ì•„ ì±—ë´‡ ë¬¸ì œ ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸

import os
import sys
import torch
import requests
import json
from pathlib import Path

def print_section(title):
    print("\n" + "=" * 60)
    print(f"ğŸ” {title}")
    print("=" * 60)

def check_files():
    """í•„ìˆ˜ íŒŒì¼ë“¤ ì¡´ì¬ í™•ì¸"""
    print_section("íŒŒì¼ ì¡´ì¬ í™•ì¸")
    
    required_files = [
        "main.py", "app.py", "api_keys.py", "jia_persona.txt",
        "services/intent_classifier.py", "services/story_generator.py", 
        "services/code_generator.py", "services/chat_handlers.py",
        "utils/memory_builder.py", "utils/summarizer.py"
    ]
    
    for file in required_files:
        if os.path.exists(file):
            print(f"âœ… {file} - ì¡´ì¬")
        else:
            print(f"âŒ {file} - ì—†ìŒ")

def check_api_keys():
    """API í‚¤ í™•ì¸"""
    print_section("API í‚¤ í™•ì¸")
    
    try:
        from api_keys import GOOGLE_API_KEY, OPENROUTER_API_KEY
        
        if GOOGLE_API_KEY and len(GOOGLE_API_KEY.strip()) > 10:
            print(f"âœ… Google API Key: ì„¤ì •ë¨ ({len(GOOGLE_API_KEY)}ì)")
        else:
            print("âŒ Google API Key: ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            
        if OPENROUTER_API_KEY and len(OPENROUTER_API_KEY.strip()) > 10:
            print(f"âœ… OpenRouter API Key: ì„¤ì •ë¨ ({len(OPENROUTER_API_KEY)}ì)")
        else:
            print("âŒ OpenRouter API Key: ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            
    except ImportError as e:
        print(f"âŒ api_keys.py ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"âŒ API í‚¤ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")

def check_model_path():
    """ëª¨ë¸ ê²½ë¡œ í™•ì¸"""
    print_section("ëª¨ë¸ ê²½ë¡œ í™•ì¸")
    
    model_path = r"F:\venv\MiniCPM-V"
    print(f"ğŸ“‚ í™•ì¸í•  ê²½ë¡œ: {model_path}")
    
    if os.path.exists(model_path):
        print("âœ… ëª¨ë¸ í´ë” ì¡´ì¬")
        
        # ëª¨ë¸ íŒŒì¼ë“¤ í™•ì¸
        model_files = [
            "config.json", "tokenizer_config.json", 
            "pytorch_model.bin", "model.safetensors"
        ]
        
        for file in model_files:
            file_path = os.path.join(model_path, file)
            if os.path.exists(file_path):
                size = os.path.getsize(file_path) / (1024*1024)  # MB
                print(f"  âœ… {file} ({size:.1f} MB)")
            else:
                print(f"  â“ {file} - ì—†ìŒ (ì„ íƒì )")
                
    else:
        print("âŒ ëª¨ë¸ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        print("ğŸ’¡ í•´ê²°ì±…: python download_model.py ì‹¤í–‰")

def test_torch():
    """PyTorch ë° CUDA í™•ì¸"""
    print_section("PyTorch í™˜ê²½ í™•ì¸")
    
    print(f"ğŸ Python ë²„ì „: {sys.version}")
    print(f"ğŸ”¥ PyTorch ë²„ì „: {torch.__version__}")
    print(f"ğŸ® CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"ğŸ¯ CUDA ë²„ì „: {torch.version.cuda}")
        print(f"ğŸ“Š GPU ê°œìˆ˜: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            name = torch.cuda.get_device_name(i)
            memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
            print(f"  GPU {i}: {name} ({memory:.1f} GB)")

def test_imports():
    """í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸"""
    print_section("ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸")
    
    test_imports = [
        "torch", "transformers", "fastapi", "uvicorn", 
        "streamlit", "requests", "PIL", "psutil"
    ]
    
    for lib in test_imports:
        try:
            __import__(lib)
            print(f"âœ… {lib}")
        except ImportError as e:
            print(f"âŒ {lib}: {e}")

def test_model_loading():
    """ê°„ë‹¨í•œ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print_section("ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    
    try:
        from transformers import AutoTokenizer
        
        model_path = r"F:\venv\MiniCPM-V"
        
        if not os.path.exists(model_path):
            print("âŒ ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ë¡œë”© í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€")
            return
            
        print("ğŸ”¤ í† í¬ë‚˜ì´ì € ë¡œë”© í…ŒìŠ¤íŠ¸...")
        tokenizer = AutoTokenizer.from_pretrained(
            model_path, 
            trust_remote_code=True
        )
        print("âœ… í† í¬ë‚˜ì´ì € ë¡œë”© ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í† í°í™” í…ŒìŠ¤íŠ¸
        test_text = "ì•ˆë…•í•˜ì„¸ìš”"
        tokens = tokenizer.encode(test_text)
        decoded = tokenizer.decode(tokens)
        print(f"ğŸ§ª í† í°í™” í…ŒìŠ¤íŠ¸: '{test_text}' â†’ {len(tokens)}ê°œ í† í° â†’ '{decoded}'")
        
        print("âš ï¸ ì „ì²´ ëª¨ë¸ ë¡œë”©ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ê±´ë„ˆëœ€")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def test_backend_connection():
    """ë°±ì—”ë“œ ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print_section("ë°±ì—”ë“œ ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸")
    
    backend_url = "http://localhost:8001"
    
    try:
        response = requests.get(f"{backend_url}/", timeout=5)
        if response.status_code == 200:
            print("âœ… ë°±ì—”ë“œ ì„œë²„ ì—°ê²° ì„±ê³µ")
            
            data = response.json()
            print(f"ğŸ“„ ì„œë²„ ì •ë³´:")
            print(f"  ë²„ì „: {data.get('version', 'N/A')}")
            print(f"  ê¸°ëŠ¥: {', '.join(data.get('features', []))}")
            
            # ëª¨ë¸ ìƒíƒœ í™•ì¸
            try:
                status_response = requests.get(f"{backend_url}/model-status", timeout=5)
                if status_response.status_code == 200:
                    status = status_response.json()
                    print(f"ğŸ¤– ëª¨ë¸ ìƒíƒœ:")
                    
                    minicpm = status.get("minicpm_model", {})
                    print(f"  MiniCPM-V ë¡œë“œë¨: {minicpm.get('loaded', False)}")
                    print(f"  ë””ë°”ì´ìŠ¤: {minicpm.get('device', 'N/A')}")
                    
                    memory = status.get("memory_system", {})
                    print(f"  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ: {memory.get('loaded', False)}")
                    
            except Exception as e:
                print(f"âš ï¸ ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
                
        else:
            print(f"âŒ ë°±ì—”ë“œ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            
    except requests.exceptions.ConnectionError:
        print("âŒ ë°±ì—”ë“œ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŒ")
        print("ğŸ’¡ í•´ê²°ì±…: python manage_servers.py start")
    except Exception as e:
        print(f"âŒ ë°±ì—”ë“œ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def test_chat_request():
    """ê°„ë‹¨í•œ ì±„íŒ… ìš”ì²­ í…ŒìŠ¤íŠ¸"""
    print_section("ì±„íŒ… ìš”ì²­ í…ŒìŠ¤íŠ¸")
    
    backend_url = "http://localhost:8001"
    
    try:
        test_message = "ì•ˆë…•"
        print(f"ğŸ“¤ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡: '{test_message}'")
        
        response = requests.post(
            f"{backend_url}/chat",
            json={"message": test_message},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get("response", "ì‘ë‹µ ì—†ìŒ")
            print(f"ğŸ“¥ ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ:")
            print(f"  ê¸¸ì´: {len(answer)}ì")
            print(f"  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {answer[:100]}...")
            
            if "ìŒ... ì§€ê¸ˆ ì¢€ ë³µì¡í•œ ìƒê°ì„ í•˜ê³  ìˆì–´ì„œ" in answer:
                print("âš ï¸ ì—¬ì „íˆ ê¸°ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ë‚˜íƒ€ë‚¨!")
            else:
                print("âœ… ì •ìƒì ì¸ ì‘ë‹µì„ ë°›ìŒ!")
                
        else:
            print(f"âŒ ì±„íŒ… ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            try:
                error = response.json()
                print(f"  ì˜¤ë¥˜ ë‚´ìš©: {error}")
            except:
                print(f"  ì‘ë‹µ í…ìŠ¤íŠ¸: {response.text}")
                
    except Exception as e:
        print(f"âŒ ì±„íŒ… ìš”ì²­ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def create_minimal_test():
    """ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸ìš© main.py ìƒì„±"""
    print_section("ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸ ì½”ë“œ ìƒì„±")
    
    minimal_code = '''
# minimal_test.py - ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸ìš© FastAPI ì„œë²„
from fastapi import FastAPI
import uvicorn

app = FastAPI()

@app.get("/")
def read_root():
    return {"message": "ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸ ì„œë²„", "status": "OK"}

@app.post("/chat")
def simple_chat(request: dict):
    user_message = request.get("message", "")
    
    # ê°„ë‹¨í•œ ì‘ë‹µ ë¡œì§
    if "ì•ˆë…•" in user_message:
        response = "ì•ˆë…• ë‹´! ë‚˜ëŠ” ì§€ì•„ì•¼. í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆì–´!"
    elif "ì´ë¦„" in user_message:
        response = "ë‚´ ì´ë¦„ì€ ì§€ì•„ì•¼! ì§€ê¸ˆì€ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì´ì•¼."
    else:
        response = f"ë„ˆê°€ '{user_message}'ë¼ê³  í–ˆêµ¬ë‚˜! í…ŒìŠ¤íŠ¸ ì‘ë‹µì´ì•¼."
    
    return {"response": response}

if __name__ == "__main__":
    print("ğŸ§ª ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸ ì„œë²„ ì‹œì‘")
    uvicorn.run("minimal_test:app", host="0.0.0.0", port=8001, reload=False)
'''
    
    with open("minimal_test.py", "w", encoding="utf-8") as f:
        f.write(minimal_code.strip())
    
    print("âœ… minimal_test.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ğŸ”§ í…ŒìŠ¤íŠ¸ ë°©ë²•:")
    print("  1. python minimal_test.py")
    print("  2. ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8001 ì ‘ì†")
    print("  3. Streamlitì—ì„œ ì±„íŒ… í…ŒìŠ¤íŠ¸")

def main():
    """ë©”ì¸ ì§„ë‹¨ ì‹¤í–‰"""
    print("ğŸ” ì§€ì•„ ì±—ë´‡ ì¢…í•© ì§„ë‹¨ ì‹œì‘")
    print("=" * 60)
    
    # 1. ê¸°ë³¸ í™˜ê²½ í™•ì¸
    check_files()
    check_api_keys()
    test_imports()
    test_torch()
    
    # 2. ëª¨ë¸ ê´€ë ¨ í™•ì¸
    check_model_path()
    test_model_loading()
    
    # 3. ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
    test_backend_connection()
    test_chat_request()
    
    # 4. ë¬¸ì œ í•´ê²° ì œì•ˆ
    print_section("ë¬¸ì œ í•´ê²° ì œì•ˆ")
    
    print("ğŸ› ï¸ ì¶”ì²œ í•´ê²° ìˆœì„œ:")
    print("1. ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸ ì„œë²„ ì‹¤í–‰:")
    print("   python debug_jia.py && python minimal_test.py")
    print()
    print("2. ëª¨ë¸ ì—†ì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸")
    print("3. API í‚¤ ì„¤ì • í™•ì¸")
    print("4. ì›ë³¸ main.py ë¬¸ì œ í™•ì¸")
    print()
    print("ğŸ’¡ ì¦‰ì‹œ í•´ê²°ì±…:")
    print("- minimal_test.pyë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    
    answer = input().strip().lower()
    if answer in ['y', 'yes', 'ì˜ˆ']:
        create_minimal_test()
    
    print("\nğŸ¯ ì§„ë‹¨ ì™„ë£Œ!")

if __name__ == "__main__":
    main()